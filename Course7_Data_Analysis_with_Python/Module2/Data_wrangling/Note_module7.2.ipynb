{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a52508-bc73-45b5-8dec-2eaa1baaf1d3",
   "metadata": {},
   "source": [
    "### Module 2: Data Wrangling\n",
    "\n",
    "Data pre-processing techniques necessary for data analysis, often referred to as data cleaning or data wrangling. Key topics covered include:\n",
    "\n",
    "1. Identifying and Handling Missing Values:\n",
    "   - Missing values occur when data entries are left empty.\n",
    "   - Methods to identify and manage these missing values will be discussed.\n",
    "\n",
    "2. Standardizing Data Formats:\n",
    "   - Data from different sources may be in various formats, units, or conventions.\n",
    "   - Methods in Python Pandas to standardize these values will be introduced.\n",
    "\n",
    "3. Data Normalization:\n",
    "   - Different numerical data columns may have varying ranges, making direct comparison difficult.\n",
    "   - Normalization techniques, such as centering and scaling, will be focused on to bring data into a similar range for better comparison.\n",
    "\n",
    "4. Data Binning:\n",
    "   - Binning creates larger categories from numerical values.\n",
    "   - This technique is useful for comparing groups of data.\n",
    "\n",
    "5. Converting Categorical Variables:\n",
    "   - Categorical values need to be converted into numeric variables for statistical modeling.\n",
    "   - Methods to perform this conversion will be demonstrated.\n",
    "\n",
    "By covering these techniques, the video aims to prepare raw data for further analysis, ensuring it is clean, standardized, and ready for meaningful comparison and statistical modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3229f5-4bbf-4313-9b7c-7290f5674dbe",
   "metadata": {},
   "source": [
    "### Managing Missing Data in Python\n",
    "\n",
    "In this video, we will introduce the pervasive problem of missing values as well as strategies on what to do when you encounter missing values in your data. \n",
    "\n",
    "#### Understanding Missing Values\n",
    "- Missing values occur when data entries are left empty or represented by symbols like question marks, N/A, zero, or blank cells.\n",
    "- Dealing with missing data is crucial for accurate analysis and modeling.\n",
    "\n",
    "#### Strategies for Handling Missing Values\n",
    "1. **Data Retrieval:** \n",
    "   - Contact the data collector to retrieve the actual missing values if possible.\n",
    "\n",
    "2. **Data Removal:**\n",
    "   - Drop the data entry or variable containing the missing value.\n",
    "   - Use `dropna()` method in Pandas to drop rows or columns with missing values (`NaN`).\n",
    "\n",
    "3. **Data Replacement:**\n",
    "   - Replace missing values with estimated values.\n",
    "   - Common techniques include replacing missing values with:\n",
    "     - Mean, median, or mode of the variable.\n",
    "     - Specific values based on domain knowledge or additional information.\n",
    "\n",
    "4. **Leave as Missing:**\n",
    "   - Sometimes, it's appropriate to leave missing values as is, especially if removing or replacing them may introduce bias or distort the data.\n",
    "\n",
    "#### Handling Missing Data in Python\n",
    "- **Removing Missing Values:**\n",
    "  - Use the `dropna()` method in Pandas to drop rows or columns with missing values.\n",
    "  - Specify `axis=0` to drop rows or `axis=1` to drop columns.\n",
    "  - Example: `dataframe.dropna(axis=0, inplace=True)` to drop rows with missing values.\n",
    "\n",
    "- **Replacing Missing Values:**\n",
    "  - Use the `replace()` method in Pandas to replace missing values with specific values.\n",
    "  - Example: `dataframe['normalized_losses'].replace(np.nan, mean_value, inplace=True)` to replace missing values in a specific column.\n",
    "\n",
    "#### Conclusion\n",
    "So we've gone through two ways in Python to deal with missing data. We learned to drop problematic rows or columns containing missing values, and then we learned how to replace missing values with other values. But don't forget the other ways to deal with missing data. You can always check for a higher quality data set or source, or in some cases, you may want to leave the missing data as missing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b387e-2fd1-4f69-a8b6-16414cf55e07",
   "metadata": {},
   "source": [
    "### Handling Data Formats in Python\n",
    "\n",
    "In this video, we'll look at the problem of data with different formats, units, and conventions and the Pandas methods that help us deal with these issues.\n",
    "\n",
    "#### Understanding Data Formatting\n",
    "- Data collected from various sources may be stored in different formats, units, or conventions.\n",
    "- Data formatting brings data into a common standard of expression, ensuring consistency and facilitating meaningful comparisons.\n",
    "\n",
    "#### Example: Standardizing Fuel Consumption Units\n",
    "- Consider a dataset with a feature named \"city-miles per gallon\" representing car fuel consumption in miles per gallon.\n",
    "- To convert miles per gallon to liters per 100 kilometers (metric version), we need to divide 235 by each value in the \"city miles per gallon\" column.\n",
    "- In Python, this transformation can be done in one line of code: `df['city-miles per gallon'] = 235 / df['city-miles per gallon']`.\n",
    "- Additionally, rename the column to \"city-liters per 100 kilometers\" using the `rename()` method:\n",
    "  ```python\n",
    "  df.rename(columns={'city-miles per gallon': 'city-liters per 100 kilometers'}, inplace=True)\n",
    "  ```\n",
    "\n",
    "#### Data Type Correction\n",
    "- Sometimes, the data type may be incorrectly established during dataset import.\n",
    "- For example, the \"price\" feature may be assigned the data type \"object\" when it should be an integer or float.\n",
    "- It's crucial to explore the data types of features and convert them to the correct data types for accurate analysis.\n",
    "- Use `dtypes` method to identify a feature's data type:\n",
    "  ```python\n",
    "  print(df.dtypes)\n",
    "  ```\n",
    "- To convert data types, use the `astype()` method. For example, to convert the \"price\" column from object to integer:\n",
    "  ```python\n",
    "  df['price'] = df['price'].astype(\"int\")\n",
    "  ```\n",
    "\n",
    "#### Conclusion\n",
    "Data formatting is an essential step in data cleaning to ensure consistency and facilitate meaningful analysis. By standardizing data formats and correcting data types, we can prepare the dataset for further analysis and modeling.\n",
    "```\n",
    "\n",
    "\n",
    "```markdown\n",
    "### Handling Data Formats in Python\n",
    "\n",
    "In this video, we'll look at the problem of data with different formats, units, and conventions and the Pandas methods that help us deal with these issues.\n",
    "\n",
    "#### Understanding Data Formatting\n",
    "- Data collected from various sources may be stored in different formats, units, or conventions.\n",
    "- Data formatting brings data into a common standard of expression, ensuring consistency and facilitating meaningful comparisons.\n",
    "\n",
    "#### Example: Standardizing Fuel Consumption Units\n",
    "- Consider a dataset with a feature named \"city-miles per gallon\" representing car fuel consumption in miles per gallon.\n",
    "- To convert miles per gallon to liters per 100 kilometers (metric version), we need to divide 235 by each value in the \"city miles per gallon\" column.\n",
    "- In Python, this transformation can be done in one line of code: \n",
    "  ```python\n",
    "  df['city-miles per gallon'] = 235 / df['city-miles per gallon']\n",
    "  ```\n",
    "- Additionally, rename the column to \"city-liters per 100 kilometers\" using the `rename()` method:\n",
    "  ```python\n",
    "  df.rename(columns={'city-miles per gallon': 'city-liters per 100 kilometers'}, inplace=True)\n",
    "  ```\n",
    "\n",
    "#### Data Type Correction\n",
    "- Sometimes, the data type may be incorrectly established during dataset import.\n",
    "- For example, the \"price\" feature may be assigned the data type \"object\" when it should be an integer or float.\n",
    "- It's crucial to explore the data types of features and convert them to the correct data types for accurate analysis.\n",
    "- Use `dtypes` method to identify a feature's data type:\n",
    "  ```python\n",
    "  print(df.dtypes)\n",
    "  ```\n",
    "- To convert data types, use the `astype()` method. For example, to convert the \"price\" column from object to integer:\n",
    "  ```python\n",
    "  df['price'] = df['price'].astype(\"int\")\n",
    "  ```\n",
    "\n",
    "#### Conclusion\n",
    "Data formatting is an essential step in data cleaning to ensure consistency and facilitate meaningful analysis. By standardizing data formats and correcting data types, we can prepare the dataset for further analysis and modeling.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36240be9-ba9e-48e1-b998-b4b66430195c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this video, we explore the challenges of dealing with data in different formats, units, and conventions, and the Pandas methods that help address these issues. Data collected from various sources can often have inconsistent formats, making it necessary to standardize the data for meaningful analysis.\n",
    "\n",
    "### Key Points\n",
    "\n",
    "1. **Data Formatting**: \n",
    "    - Data formatting involves standardizing the expression of data to allow for meaningful comparisons.\n",
    "    - Example: Representations of \"New York City\" such as \"N.Y.\", \"Ny\", \"NY\", and \"New York\" need to be standardized unless analyzing variations is the goal.\n",
    "\n",
    "2. **Unit Conversion**:\n",
    "    - Converting units ensures consistency, particularly when data is used internationally.\n",
    "    - Example: Converting fuel consumption from miles per gallon (mpg) to liters per 100 kilometers (L/100km) using the formula: \n",
    "      \\[\n",
    "      \\text{city\\_liters per 100 kilometers} = \\frac{235}{\\text{city miles per gallon}}\n",
    "      \\]\n",
    "    - In Python:\n",
    "      ```python\n",
    "      df['city-liters per 100 kilometers'] = 235 / df['city-miles per gallon']\n",
    "      df.rename(columns={'city-miles per gallon': 'city-liters per 100 kilometers'}, inplace=True)\n",
    "      ```\n",
    "\n",
    "3. **Correcting Data Types**:\n",
    "    - Incorrect data types can lead to errors in analysis and model development.\n",
    "    - Example: A price column might be incorrectly set as an object instead of a numerical type (integer or float).\n",
    "    - To identify data types, use:\n",
    "      ```python\n",
    "      df.dtypes\n",
    "      ```\n",
    "    - To convert data types, use:\n",
    "      ```python\n",
    "      df['price'] = df['price'].astype(int)\n",
    "      ```\n",
    "\n",
    "### Practical Examples\n",
    "\n",
    "- **Standardizing Text Data**:\n",
    "  ```python\n",
    "  df['city'] = df['city'].str.replace('N.Y.', 'New York')\n",
    "  df['city'] = df['city'].str.replace('Ny', 'New York')\n",
    "  df['city'] = df['city'].str.replace('NY', 'New York')\n",
    "  ```\n",
    "\n",
    "- **Unit Conversion Example**:\n",
    "  ```python\n",
    "  df['city-liters per 100 kilometers'] = 235 / df['city-miles per gallon']\n",
    "  df.rename(columns={'city-miles per gallon': 'city-liters per 100 kilometers'}, inplace=True)\n",
    "  ```\n",
    "\n",
    "- **Converting Data Types**:\n",
    "  ```python\n",
    "  df['price'] = df['price'].astype(float)\n",
    "  ```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Standardizing data formats, units, and correcting data types are essential steps in data cleaning to ensure accurate and meaningful analysis. Pandas provides powerful methods like `replace`, `rename`, and `astype` to facilitate these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6d019c-e43b-4f81-a0f2-a3f433d36a5b",
   "metadata": {},
   "source": [
    "# Data Normalization in Machine Learning\n",
    "\n",
    "This markdown provides a comprehensive overview of data normalization, a fundamental technique in machine learning for preparing data for analysis and modeling.\n",
    "\n",
    "**Understanding Normalization**\n",
    "\n",
    "Data normalization refers to the process of transforming features within a dataset to have a consistent value range. This is particularly important when dealing with datasets containing features measured on vastly different scales. Normalization ensures that all features contribute equally to statistical analyses and machine learning models, preventing features with larger scales from dominating the results.\n",
    "\n",
    "**Importance of Normalization**\n",
    "\n",
    "There are two primary reasons why normalization is crucial in machine learning:\n",
    "\n",
    "1. **Enhanced Statistical Analysis:** Many statistical methods employed in machine learning rely on the assumption that features have comparable scales. Normalization ensures features contribute equally to analyses, leading to more reliable and interpretable results.\n",
    "\n",
    "2. **Fairer Model Building:** When features have significantly different scales, machine learning algorithms like linear regression can become biased towards features with larger values. Normalization mitigates this bias by placing all features on a similar scale, fostering fairer model behavior and more accurate predictions.\n",
    "\n",
    "**Illustrative Example: Age vs. Income**\n",
    "\n",
    "Consider a dataset with two features: age (ranging from 0 to 100) and income (ranging from 0 to potentially millions). Without normalization, income's vast range would overwhelm age in analyses like linear regression. By normalizing both features to a range like 0-1, we ensure that both features contribute equally to the model and prevent income from biasing the results towards higher incomes.\n",
    "\n",
    "**Common Normalization Techniques**\n",
    "\n",
    "Several effective normalization techniques are used in machine learning. Here, we explore three prominent methods:\n",
    "\n",
    "1. **Simple Feature Scaling:** This method scales each feature by dividing its values by the maximum value within that feature. The resulting values typically range from 0 to 1.\n",
    "\n",
    "2. **Min-Max Scaling:** This technique transforms each feature value by subtracting the minimum value in the feature and then dividing by the range (difference between maximum and minimum). Similar to simple scaling, the resulting values fall between 0 and 1. \n",
    "\n",
    "3. **Z-score Normalization (Standardization):** This method calculates the mean (average) and standard deviation of each feature. Each value is then transformed by subtracting the mean and dividing by the standard deviation. The resulting values typically cluster around 0, with a range of -3 to +3 (although they can fall outside this range).\n",
    "\n",
    "**Implementation Considerations**\n",
    "\n",
    "While this summary omits specific code examples, it's important to note that popular libraries like Pandas in Python provide functionalities for all these normalization techniques. The choice of normalization technique can depend on the specific data and modeling requirements.\n",
    "\n",
    "By effectively applying data normalization techniques, you can significantly improve the fairness, accuracy, and overall effectiveness of your machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e193b-aff6-44a1-b75b-ad296c1900f4",
   "metadata": {},
   "source": [
    "## Data Binning for Preprocessing and Analysis in Python\n",
    "\n",
    "This markdown explains data binning, a technique for grouping numerical data into categories (bins) for better understanding and model building.\n",
    "\n",
    "**What is Binning?**\n",
    "\n",
    "Binning involves dividing a continuous numerical feature into a set of discrete intervals (bins). It's like grouping similar values together.\n",
    "\n",
    "**Benefits of Binning**\n",
    "\n",
    "* **Improved Model Accuracy:** Binning can sometimes improve the accuracy of predictive models by simplifying the data and reducing noise.\n",
    "* **Data Understanding:** Binning helps visualize the distribution of data by creating categories. It can reveal patterns or trends in the data that might be hidden in raw numerical values.\n",
    "\n",
    "**Example: Analyzing Car Prices**\n",
    "\n",
    "Imagine a \"price\" feature in a car dataset, ranging from $5,000 to $45,500. Binning allows us to categorize these prices into groups like \"low,\" \"medium,\" and \"high\" for better comprehension.\n",
    "\n",
    "**Binning Implementation in Python**\n",
    "\n",
    "Here's how to implement binning with Python libraries:\n",
    "\n",
    "1. **Define Bins:** Decide on the number of bins and their ranges. We'll create three bins (low, medium, high) of equal width.\n",
    "\n",
    "2. **Calculate Bin Dividers:** Use NumPy's `linspace` function to generate equally spaced dividers between the minimum and maximum price values.\n",
    "\n",
    "3. **Assign Bin Names:** Create a list of names for each bin (e.g., \"low_price,\" \"medium_price,\" \"high_price\").\n",
    "\n",
    "4. **Binning Data:** Use Pandas' `cut` function to segment the \"price\" feature values into the corresponding bins based on the dividers.\n",
    "\n",
    "5. **Visualize Results:** Employ histograms to visualize the distribution of data after binning. This can reveal patterns like how many cars fall into each price category.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "Binning is a valuable technique for transforming continuous numerical data into discrete categories. It can lead to improved model performance and provide a clearer understanding of data distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a1c3c5-8cc1-4f14-9005-f06997adbcc1",
   "metadata": {},
   "source": [
    "## One-Hot Encoding Categorical Variables in Python\n",
    "\n",
    "This markdown summarizes converting categorical variables into quantitative variables in Python for machine learning models.\n",
    "\n",
    "**Why One-Hot Encoding?**\n",
    "\n",
    "Many statistical models require numerical inputs, while categorical variables contain strings or text labels. One-hot encoding addresses this by transforming categorical variables into numerical features suitable for modeling.\n",
    "\n",
    "**Example: Fuel Type in Cars**\n",
    "\n",
    "Consider a car dataset with a \"fuel type\" feature containing values like \"gas\" and \"diesel\" (categorical). To use this feature in a model, we need to convert it to a numerical format.\n",
    "\n",
    "**One-Hot Encoding Technique**\n",
    "\n",
    "One-hot encoding introduces new features (dummy variables) for each unique category in the original categorical variable. Each new feature represents a specific category.\n",
    "\n",
    "* A value of 1 indicates membership in that category.\n",
    "* A value of 0 indicates non-membership.\n",
    "\n",
    "**Example: Encoding \"Fuel Type\"**\n",
    "\n",
    "The original \"fuel type\" feature has two categories: \"gas\" and \"diesel.\" We create two new features: \"gas\" and \"diesel.\"\n",
    "\n",
    "* For cars with \"gas,\" the \"gas\" feature is set to 1, and \"diesel\" is set to 0.\n",
    "* For cars with \"diesel,\" the \"diesel\" feature is set to 1, and \"gas\" is set to 0.\n",
    "\n",
    "This effectively converts the categorical information into numerical representations for modeling purposes.\n",
    "\n",
    "**One-Hot Encoding in Pandas**\n",
    "\n",
    "Pandas provides the `get_dummies` method for conveniently converting categorical variables into dummy variables.\n",
    "\n",
    "**Example Code (Using `get_dummies`):**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "data = {'fuel_type': ['gas', 'diesel', 'gas']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# One-hot encoding using get_dummies\n",
    "dummy_variables_one = pd.get_dummies(df['fuel_type'])\n",
    "\n",
    "# Resulting data frame with dummy variables\n",
    "print(dummy_variables_one)\n",
    "```\n",
    "\n",
    "By using one-hot encoding, you can prepare your categorical data for use in various machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b41da4-d7d6-4465-a05f-49a6051082c4",
   "metadata": {},
   "source": [
    "## Data Preprocessing Techniques\n",
    "\n",
    "This summary highlights the key data preprocessing techniques covered in this lesson, equipping you to effectively prepare data for machine learning models.\n",
    "\n",
    "**Data Formatting**\n",
    "\n",
    "* Standardize data formats (e.g., capitalization, abbreviations) for consistent analysis.\n",
    "* Ensure data from different sources are comparable by addressing inconsistencies.\n",
    "\n",
    "**Unit Conversion**\n",
    "\n",
    "* Convert units of measurement (e.g., miles per gallon to liters per 100 kilometers) for better analysis and interpretation.\n",
    "* Utilize Python libraries like Pandas to perform unit conversions for numerical features.\n",
    "\n",
    "**Data Type Handling**\n",
    "\n",
    "* Identify and correct data types using Python methods (e.g., Pandas `dtypes`) to ensure accurate analysis.\n",
    "* Convert data to appropriate numerical types (e.g., integer, float) for proper calculations in statistical models.\n",
    "\n",
    "**Data Normalization**\n",
    "\n",
    "* Normalize data to make features comparable and mitigate biases in statistical models.\n",
    "* Apply techniques like Feature Scaling, Min-Max Scaling, and Z-Score Normalization in Python using Pandas methods.\n",
    "\n",
    "**Data Binning**\n",
    "\n",
    "* Utilize binning to group numerical data into categories (bins) for improved model accuracy and data understanding.\n",
    "* Implement binning in Python with NumPy's `linspace` function for creating bins and Pandas' `cut` function for assigning data points to bins.\n",
    "* Leverage histograms to visualize the distribution of binned data to gain insights into feature behavior.\n",
    "\n",
    "**One-Hot Encoding**\n",
    "\n",
    "* Convert categorical variables (e.g., \"fuel type\") into numerical representations suitable for machine learning models.\n",
    "* Employ one-hot encoding to create dummy variables in Python using Pandas' `get_dummies` method. Each dummy variable represents a category within the original feature.\n",
    "\n",
    "By mastering these techniques, you can effectively prepare your data for machine learning, leading to more robust and accurate models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74850268-215d-414e-84eb-a8e7a0065ecb",
   "metadata": {},
   "source": [
    "# Practice Quiz: Data Wrangling\n",
    "\n",
    "**Assignment details**\n",
    "- **Submitted:** June 10, 12:43 AM +07Jun 10, 12:43 AM +07\n",
    "- **Attempts:** Unlimited\n",
    "- **Your grade:** To pass you need at least 75%. We keep your highest score.\n",
    "  **Grade:** 100%\n",
    "\n",
    "## Practice Quiz: Data Wrangling\n",
    "**Practice Assignment • 12 min**\n",
    "\n",
    "### 1. Question 1\n",
    "What is the correct syntax to access a column, say \"symboling,” from a dataframe, say df?\n",
    "\n",
    "1 point\n",
    "\n",
    "- [ ] `df.get(\"symboling\")`\n",
    "- [ ] `df==\"symboling\"`\n",
    "- [ ] `df=”symboling”`\n",
    "- [x] `df[\"symboling\"]`\n",
    "\n",
    "### 2. Question 2\n",
    "How would you change the name of the column \"city_mpg\" to \"city-L/100km\"?\n",
    "\n",
    "1 point\n",
    "\n",
    "- [x] `df.rename(columns={\"city_mpg\": \"city-L/100km\"})`\n",
    "- [ ] `df.rename(columns={\"city_mpg\": \"city-L/100km\"}, inplace=True)`\n",
    "- [ ] `df.columnheader(columns={\"city_mpg\": \"city-L/100km\"}, inplace=True)`\n",
    "- [ ] `df.columnname={\"city_mpg\": \"city-L/100km\"})`\n",
    "\n",
    "### 3. Question 3\n",
    "What is the primary purpose of normalization?\n",
    "\n",
    "1 point\n",
    "\n",
    "- [x] To make the range of the values consistent and make comparing and analyzing values easier\n",
    "- [ ] So all the variables have a similar influence on the models you build\n",
    "- [ ] To get rid of “not a number” or NaN values\n",
    "- [ ] It brings data into a common standard of expression\n",
    "\n",
    "### 4. Question 4\n",
    "Why do we convert categorical variables into numerical values?\n",
    "\n",
    "1 point\n",
    "\n",
    "- [ ] To save memory\n",
    "- [x] Most statistical models require numerical values\n",
    "- [ ] It makes it easier to visualize the data\n",
    "- [ ] It makes it easier to fill in missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703a088-e6c5-45d1-a6f1-836110783401",
   "metadata": {},
   "source": [
    "\n",
    "# Practice Quiz: Data Wrangling\n",
    "\n",
    "## Question 1\n",
    "Which of the following methods should you use to replace a missing value of an attribute with continuous values?\n",
    "\n",
    "1 point\n",
    "\n",
    "- [x] Use the average of the other values in the column\n",
    "- [ ] Use the difference between the minimum and maximum values of the other data in the column\n",
    "- [ ] Use the mean square error of the other data in the column\n",
    "- [ ] Use an educated guess\n",
    "\n",
    "## Question 2\n",
    "Which of the following helps you decide on bin values when pre-processing data?\n",
    "\n",
    "1 point\n",
    "\n",
    "- [x] Visualize the distribution using a histogram\n",
    "- [ ] Divide the average by the standard deviation\n",
    "- [ ] Convert objects to ints\n",
    "- [ ] Use the interquartile range\n",
    "\n",
    "## Question 3\n",
    "Which of the following data types should numbers with decimals be if you want to use them as input for training a statistical model?\n",
    "\n",
    "666, 1.1, 232, 23.12\n",
    "\n",
    "1 point\n",
    "\n",
    "- [ ] int\n",
    "- [ ] data frame\n",
    "- [x] float\n",
    "- [ ] object\n",
    "\n",
    "## Question 4\n",
    "Which of the following is the primary purpose of simple feature scaling?\n",
    "\n",
    "1 point\n",
    "\n",
    "- [ ] It brings data into a common standard of expression\n",
    "- [x] To make comparing and analyzing values easier.\n",
    "- [ ] To get rid of “not a number” or NaN values\n",
    "- [ ] So all the variables have a similar influence on the models you build\n",
    "\n",
    "## Question 5\n",
    "Which of the following is the primary purpose of the get_dummies() method?\n",
    "\n",
    "1 point\n",
    "\n",
    "- [ ] Converts the data’s data type\n",
    "- [ ] To help you group your data into bins\n",
    "- [x] Converts categorical values into numerical ones\n",
    "- [ ] Converts numerical values into categorical ones\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52f42b3-f615-461f-932f-fadd1d202899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
